# SparkConnectService

`SparkConnectService` is a `BindableService` ([gRPC]({{ grpc.api }}/io/grpc/BindableService.html)).

`SparkConnectService` is [started](#start) as a [gRPC service](#startGRPCService) for the following:

* Apache Spark applications (as a [Spark driver plugin](SparkConnectPlugin.md#driverPlugin))
* On command line as a [SparkConnectServer](SparkConnectServer.md) standalone application

Right after having been [started](#start), `SparkConnectService` [posts a SparkListenerConnectServiceStarted event](#postSparkConnectServiceStarted) with all the network connectivity information.

## Creating Instance

`SparkConnectService` takes the following to be created:

* <span id="debug"> `debug` flag

`SparkConnectService` is created when:

* `SparkConnectService` is requested to [start a gRPC service](#startGRPCService)

## gRPC Server { #server }

`SparkConnectService` creates and starts a `Server` ([gRPC]({{ grpc.api }}/io/grpc/Server.html)) when [starting the gRPC Service](#startGRPCService).

## Start Spark Connect Service { #start }

```scala
start(
  sc: SparkContext): Unit
```

`start` [starts the gRPC service](#startGRPCService) and then [creates a listener and the UI](#createListenerAndUI).

In the end, `start` [posts a SparkListenerConnectServiceStarted event](#postSparkConnectServiceStarted).

---

`start` is used when:

* `SparkConnectPlugin` is requested for the [Spark driver plugin](SparkConnectPlugin.md#driverPlugin)
* [SparkConnectServer](SparkConnectServer.md) standalone application is started

### Start gRPC Service { #startGRPCService }

```scala
startGRPCService(): Unit
```

`startGRPCService` reads the values of the following configuration properties:

Configuration Property | Default Value
-----------------------|--------------
 [spark.connect.grpc.debug.enabled](configuration-properties.md#spark.connect.grpc.debug.enabled) | `true`
 [spark.connect.grpc.binding.port](configuration-properties.md#spark.connect.grpc.binding.port) | `15002`
 [spark.connect.grpc.maxInboundMessageSize](configuration-properties.md#spark.connect.grpc.maxInboundMessageSize) | `128 * 1024 * 1024`

`startGRPCService` builds a `NettyServerBuilder` with the `spark.connect.grpc.binding.port` and a [SparkConnectService](SparkConnectService.md).

`startGRPCService` [registers interceptors](SparkConnectInterceptorRegistry.md#chainInterceptors).

`startGRPCService` [builds the server](#server) and starts it.

### createListenerAndUI { #createListenerAndUI }

```scala
createListenerAndUI(
  sc: SparkContext): Unit
```

`createListenerAndUI` creates a [SparkConnectServerTab](SparkConnectServerTab.md) (for `spark.ui.enabled` enabled).

### Post SparkListenerConnectServiceStarted { #postSparkConnectServiceStarted }

```scala
postSparkConnectServiceStarted(): Unit
```

`postSparkConnectServiceStarted` posts a `SparkListenerConnectServiceStarted` event (with this server's [hostAddress](#hostAddress), port and the current time)

## Handle Add Artifacts Request { #addArtifacts }

??? note "Generated by gRPC Proto Compiler"

    ```scala
    addArtifacts(
      responseObserver: StreamObserver[AddArtifactsResponse]
    ): StreamObserver[AddArtifactsRequest]
    ```

    `addArtifacts` is generated by the gRPC proto compiler from `spark/connect/base.proto`.

`addArtifacts` creates a new [SparkConnectAddArtifactsHandler](SparkConnectAddArtifactsHandler.md) for the given `responseObserver`.

## Handle Analyze Plan Request { #analyzePlan }

??? note "Generated by gRPC Proto Compiler"

    ```scala
    analyzePlan(
      request: proto.AnalyzePlanRequest,
      responseObserver: StreamObserver[proto.AnalyzePlanResponse]): Unit
    ```

    `analyzePlan` is generated by the gRPC proto compiler from `spark/connect/base.proto`.

`analyzePlan` creates a new [SparkConnectAnalyzeHandler](SparkConnectAnalyzeHandler.md) to [handle](SparkConnectAnalyzeHandler.md#handle) the `AnalyzePlanRequest` request.

## Handle Execute Plan Request { #executePlan }

??? note "Generated by gRPC Proto Compiler"

    ```scala
    executePlan(
      request: proto.ExecutePlanRequest,
      responseObserver: StreamObserver[proto.ExecutePlanResponse]): Unit
    ```

    `executePlan` is generated by the gRPC proto compiler from `spark/connect/base.proto`.

`executePlan` creates a [SparkConnectExecutePlanHandler](SparkConnectExecutePlanHandler.md) to [handle](SparkConnectAnalyzeHandler.md#handle) the `ExecutePlanRequest` request.

## Handle Execute Plan Request { #releaseSession }

??? note "Generated by gRPC Proto Compiler"

    ```scala
    releaseSession(
      request: proto.ReleaseSessionRequest,
      responseObserver: StreamObserver[proto.ReleaseSessionResponse]): Unit
    ```

    `releaseSession` is generated by the gRPC proto compiler from `spark/connect/base.proto`.

`releaseSession` creates a [SparkConnectReleaseSessionHandler](SparkConnectReleaseSessionHandler.md) to [handle](SparkConnectReleaseSessionHandler.md#handle) the `ReleaseSessionRequest` request.

## Logging

Enable `ALL` logging level for `org.apache.spark.sql.connect.service.SparkConnectService` logger to see what happens inside.

Add the following line to `conf/log4j2.properties`:

```text
logger.SparkConnectService.name = org.apache.spark.sql.connect.service.SparkConnectService
logger.SparkConnectService.level = all
```

Refer to [Logging](../logging.md).
